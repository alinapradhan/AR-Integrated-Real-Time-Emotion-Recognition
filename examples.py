#!/usr/bin/env python3
"""
Example usage script for AR-Integrated Real-Time Emotion Recognition.
This script demonstrates how to use the system with the FER2013 dataset.
"""

import os
import sys
import numpy as np

# Add src to path for imports
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

def example_dataset_loading():
    """Example of loading and using FER2013 dataset."""
    print("ğŸ“Š Example: Loading FER2013 Dataset")
    print("-" * 40)
    
    from data_loader import FER2013DataLoader
    
    # Initialize data loader
    loader = FER2013DataLoader()
    
    print(f"Dataset path: {loader.data_path}")
    print(f"Emotion classes: {loader.emotions}")
    print(f"Number of classes: {loader.num_classes}")
    
    # Check if dataset exists
    if not os.path.exists(loader.data_path):
        print("âš ï¸  Dataset not found. To download:")
        print("1. Set up Kaggle API credentials")
        print("2. Run: python setup.py")
        print("3. Or download manually from Kaggle")
        return False
    
    try:
        # Load dataset
        print("\nğŸ“¥ Loading dataset...")
        faces, emotions = loader.load_data()
        
        print(f"âœ… Loaded {faces.shape[0]} face images")
        print(f"âœ… Image shape: {faces.shape[1:]}")
        print(f"âœ… Emotion labels shape: {emotions.shape}")
        
        # Split data
        (X_train, y_train), (X_val, y_val), (X_test, y_test) = loader.split_data(faces, emotions)
        
        print(f"\nğŸ“Š Data splits:")
        print(f"   Training: {X_train.shape[0]} samples")
        print(f"   Validation: {X_val.shape[0]} samples") 
        print(f"   Test: {X_test.shape[0]} samples")
        
        # Show emotion distribution
        print(f"\nğŸ˜Š Emotion distribution in training set:")
        for i, emotion in enumerate(loader.emotions):
            count = np.sum(np.argmax(y_train, axis=1) == i)
            percentage = (count / len(y_train)) * 100
            print(f"   {emotion}: {count} samples ({percentage:.1f}%)")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error loading dataset: {e}")
        return False

def example_model_training():
    """Example of training emotion recognition model."""
    print("\nğŸ§  Example: Model Training")
    print("-" * 40)
    
    from emotion_model import EmotionCNN
    
    # Initialize model
    cnn = EmotionCNN(input_shape=(48, 48, 1), num_classes=7)
    
    # Build and compile model
    cnn.build_model()
    cnn.compile_model(learning_rate=0.001)
    
    print("âœ… Model architecture:")
    cnn.summary()
    
    print(f"\nğŸ”§ Training configuration:")
    print(f"   - Input shape: {cnn.input_shape}")
    print(f"   - Number of classes: {cnn.num_classes}")
    print(f"   - Optimizer: Adam")
    print(f"   - Loss: Categorical crossentropy")
    
    # Note: Actual training would require dataset
    print(f"\nğŸ“ To train the model:")
    print(f"   python main.py train")
    
    return True

def example_real_time_detection():
    """Example of real-time emotion detection setup."""
    print("\nğŸ“¹ Example: Real-time Detection")
    print("-" * 40)
    
    from real_time_detector import RealTimeEmotionDetector
    
    # Initialize detector
    detector = RealTimeEmotionDetector()
    
    print(f"Model path: {detector.model_path}")
    print(f"Emotion labels: {detector.emotion_labels}")
    print(f"Emotion colors: {list(detector.emotion_colors.keys())}")
    
    print(f"\nğŸ¯ Features:")
    print(f"   - MediaPipe face detection")
    print(f"   - Real-time emotion classification")
    print(f"   - Bounding box visualization")
    print(f"   - Confidence display")
    
    print(f"\nğŸ“ To run real-time detection:")
    print(f"   python main.py detect")
    
    return True

def example_ar_overlay():
    """Example of AR emotion overlay features."""
    print("\nâœ¨ Example: AR Emotion Overlay")
    print("-" * 40)
    
    from ar_emotion_overlay import AREmotionOverlay
    
    # Initialize AR overlay
    ar_overlay = AREmotionOverlay()
    
    print(f"Emotion emojis: {ar_overlay.emotion_emojis}")
    print(f"AR colors: {list(ar_overlay.emotion_colors.keys())}")
    
    print(f"\nğŸ¨ AR Features:")
    print(f"   - Emotion-based color coding")
    print(f"   - Dynamic particle effects")
    print(f"   - Confidence visualization")
    print(f"   - Interactive overlays")
    
    print(f"\nğŸ† Particle effects:")
    print(f"   - Happy: Sparkles and stars")
    print(f"   - Angry: Fire-like particles")
    print(f"   - Sad: Tear drops")
    
    print(f"\nğŸ“ To run AR overlay:")
    print(f"   python main.py ar")
    
    return True

def show_system_overview():
    """Show complete system overview."""
    print("\nğŸ­ System Overview")
    print("=" * 50)
    
    print("\nğŸ“‹ Core Components:")
    print("   1. ğŸ“Š FER2013 Data Loader - Dataset handling and preprocessing")
    print("   2. ğŸ§  CNN Model - Deep learning architecture for emotion recognition")  
    print("   3. ğŸ“¹ Real-time Detector - Live webcam emotion detection")
    print("   4. âœ¨ AR Overlay - Augmented reality visualization")
    
    print("\nğŸ¯ Supported Emotions:")
    emotions = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']
    for i, emotion in enumerate(emotions):
        print(f"   {i}: {emotion}")
    
    print("\nâš™ï¸ Technical Specifications:")
    print("   - Input: 48x48 grayscale images")
    print("   - Model: Convolutional Neural Network")
    print("   - Face Detection: MediaPipe")
    print("   - Real-time Performance: Optimized for webcam")
    
    print("\nğŸš€ Usage Modes:")
    print("   - train: Train model on FER2013 dataset")
    print("   - detect: Real-time emotion detection")  
    print("   - ar: AR-enhanced emotion visualization")

def main():
    """Run all examples."""
    print("ğŸ­ AR-Integrated Real-Time Emotion Recognition Examples")
    print("=" * 60)
    
    try:
        # Show system overview
        show_system_overview()
        
        # Run examples
        example_dataset_loading()
        example_model_training()
        example_real_time_detection()
        example_ar_overlay()
        
        print("\n" + "=" * 60)
        print("âœ… All examples completed successfully!")
        print("\nğŸ“– For complete setup instructions, run: python setup.py")
        print("ğŸ“– For usage help, run: python main.py --help")
        
    except ImportError as e:
        print(f"âš ï¸  Some modules not available: {e}")
        print("ğŸ’¡ Install dependencies with: pip install -r requirements.txt")
    except Exception as e:
        print(f"âŒ Error running examples: {e}")

if __name__ == "__main__":
    main()